{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q9lD0PuPLSgb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CouLyWACLWf9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goQHfwh_tFR0",
        "outputId": "443d9157-b666-46e0-ffd4-1241cdf6eb93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmBhpjvauUtG",
        "outputId": "7041bd40-9679-430c-95d3-989a5d4d32c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-164-d400bed34158>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.data = torch.load(\"/content/training_data.pt\").unsqueeze(1).type(torch.float32)\n",
            "<ipython-input-164-d400bed34158>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.classes = np.array(torch.load(\"/content/training_labels.pt\"))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train = torch.load(\"/content/training_data.pt\").unsqueeze(1).type(torch.float32)\n",
        "# classes = np.array(torch.load(\"/content/training_labels.pt\"))\n",
        "\n",
        "class SymbolDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.data = torch.load(\"/strange_symbols/training_data.pt\").unsqueeze(1).type(torch.float32)\n",
        "        # np.array used as the data is loaded as a tuple\n",
        "        self.classes = np.array(torch.load(\"/strange_symbols/training_labels.pt\"))\n",
        "        self.n_samples = self.data.size()[0]\n",
        "\n",
        "        # Convert Array to Tensor\n",
        "        self.classes = torch.from_numpy(self.classes)\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index], self.classes[index]\n",
        "\n",
        "    # returns the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "data = SymbolDataset()\n",
        "train_data = data[:int(len(data)*0.8)]\n",
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCy5WBvvy4o8",
        "outputId": "b2660abf-d94e-4518-ba04-bd90089e2268"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 8,  0,  3,  ..., 10,  2, 12])"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(classes)\n",
        "torch.from_numpy(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNtwOupe2XfD",
        "outputId": "9f290f96-fea4-45fb-efa8-cbe7a1c9a4ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([15000, 1, 28, 28])"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#train = torch.from_numpy(train_array).unsqueeze(1).type(torch.float32)\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "sF0alCdRuWWb"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Resize((256, 256)),\n",
        "#     transforms.RandomResizedCrop(256)\n",
        "# ])\n",
        "transform = transforms.Normalize((0.5), (0.5))\n",
        "\n",
        "img_tensor = transform(train)\n",
        "\n",
        "#train_data = TensorDataset(train, train_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR6Zl-Se7icT",
        "outputId": "4ce49aab-a70c-4be6-cce9-ae23d56b8ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12000.0\n"
          ]
        }
      ],
      "source": [
        "train.shape\n",
        "print(np.ceil(img_tensor.size()[0]*0.8))\n",
        "ds = TensorDataset(train, torch.from_numpy(classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hOoIunSPnQdk",
        "outputId": "d1f08e58-652b-4216-84a3-e377ac9e1c18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,   1.,  39.,  73.,  73.,  73.,\n",
            "           73.,  35.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,   7.,  39.,\n",
            "           17.,   3.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,   3.,  71., 315., 429., 433., 433.,\n",
            "          433., 243.,  19.,  -1.,  -1.,  -1.,  -1.,   3.,  67., 229., 339.,\n",
            "          277., 153.,  19.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,   5., 129., 353., 491., 507., 507., 505.,\n",
            "          507., 441., 179.,  13.,  -1.,  13.,  67., 163., 353., 485., 503.,\n",
            "          499., 439., 245.,   3.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  39., 245., 443., 505., 441., 281., 229., 195.,\n",
            "          377., 503., 339.,  39.,  13., 325., 485., 503., 489., 353., 257.,\n",
            "          291., 471., 489.,  63.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1., 163., 459., 503., 413., 181.,  21.,   7.,  27.,\n",
            "          285., 489., 229.,  19., 117., 487., 505., 467., 315.,  71.,   9.,\n",
            "           71., 407., 499.,  99.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,   1., 277., 497., 437.,  93.,  13.,  -1.,  19., 181.,\n",
            "          441., 439., 101.,  95., 389., 503., 437., 191.,  39.,   1.,  -1.,\n",
            "           19., 283., 497., 203.,   5.,  -1.],\n",
            "         [ -1.,  -1.,  65., 441., 465., 191.,   1.,  -1.,   5., 245., 441.,\n",
            "          503., 315.,  81., 317., 493., 441., 181.,  17.,  -1.,  -1.,  -1.,\n",
            "           43., 345., 499., 187.,   5.,  -1.],\n",
            "         [ -1.,   7., 247., 501., 339.,  41.,  -1.,  17., 181., 491., 443.,\n",
            "          253.,  21., 163., 465., 493., 157.,   5.,  -1.,  -1.,  -1.,   5.,\n",
            "          317., 493., 489.,  91.,  -1.,  -1.],\n",
            "         [ -1.,   5., 189., 473., 197.,  11.,  43., 189., 437., 487., 253.,\n",
            "           23.,   7., 249., 497., 443.,  21.,  -1.,   3.,  41.,  73., 105.,\n",
            "          463., 493., 389.,  15.,  -1.,  -1.],\n",
            "         [ -1.,   7., 227., 493., 355., 193., 341., 463., 503., 329.,  75.,\n",
            "            9.,  17., 257., 499., 443.,  35.,  67., 163., 343., 429., 443.,\n",
            "          495., 349.,  93.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  65., 413., 497., 505., 507., 509., 481., 361., 429.,\n",
            "          433., 435., 471., 507., 505., 453., 489., 503., 499., 489., 415.,\n",
            "          165.,  39.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,   1., 117., 413., 505., 507., 507., 507., 503., 507.,\n",
            "          507., 507., 507., 507., 507., 507., 507., 487., 281., 227.,  91.,\n",
            "            5.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  13., 179., 403., 433., 433., 433., 433., 433.,\n",
            "          433., 433., 433., 433., 433., 433., 405., 251.,  21.,   7.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  13.,  63.,  73.,  73.,  73.,  73.,  73.,\n",
            "           73.,  73.,  73.,  73.,  73.,  73.,  63.,  15.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
            "           -1.,  -1.,  -1.,  -1.,  -1.,  -1.]]])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.image = train\n",
        "        self.labels = train_labels\n",
        "        self.n_samples = train.size()[0]\n",
        "\n",
        "    #dataset length\n",
        "    def __len__(self):\n",
        "        return len(self.image)\n",
        "\n",
        "    #load an one of images\n",
        "    def __getitem__(self, idx):\n",
        "        return self.image[idx], self.labels[idx]\n",
        "\n",
        "df = dataset()\n",
        "img, label = df[0]\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "eV6u9XHh4KC3"
      },
      "outputs": [],
      "source": [
        "dl = DataLoader(ds, batch_size=100, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhWE_UpX_V5V",
        "outputId": "65a53ffa-dbc1-4d4f-a87b-4ab7313ab691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1, 28, 28])\n",
            "<bound method Tensor.unique of tensor([ 6, 14,  5, 10, 11,  2,  2, 10,  7,  2,  5,  0, 14,  4,  2,  8,  4, 14,\n",
            "         6, 10, 10,  5,  5,  1, 14, 10,  6, 10, 13,  5,  2,  2, 11,  0,  1,  7,\n",
            "        14,  5,  9,  1, 10, 14, 14,  2, 11,  0,  3, 12, 11,  4,  9,  7, 14,  0,\n",
            "         2,  2,  1,  5,  7,  6, 13,  6, 10, 10,  3,  8,  2, 10,  5, 12, 10,  3,\n",
            "        12, 11, 11, 12,  7,  4, 11,  1,  8,  0,  0, 14,  5,  8,  0,  5, 12,  7,\n",
            "         7, 12, 11, 13, 12,  4,  0, 12, 10,  7])>\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(dl)\n",
        "image, label = next(dataiter)\n",
        "print(image.shape)\n",
        "print(label.unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWEInng07m4r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "b0gpkF3CLpRP"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # Conv Layer 1:\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # 2x2 MaxPooling\n",
        "        # Conv Layer 2\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 15)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply conv1, relu, pool\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        print(x.shape)\n",
        "        # Apply conv2, relu, pool\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        print(x.shape)\n",
        "        # Flatten the tensor before passing it to fully connected layers\n",
        "        x = x.view(-1, 64*7*7)  # Adjust this size based on your input image size\n",
        "        print(x.shape)\n",
        "        # Fully connected layers with ReLU activations\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "OJwPsqmTF4S3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "RZgcaVpJktrC",
        "outputId": "c50a84fe-69a6-4157-9331-9cbec15904cd"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-d209abdfdc02>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Set up the loss function and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "# Set up the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3  # Adjust the number of epochs as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in dl:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        print(\"Labels:\", labels)\n",
        "        print(\"Min label:\", labels.min().item())\n",
        "        print(\"Max label:\", labels.max().item())\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track running loss and accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print loss and accuracy for the current epoch\n",
        "    epoch_loss = running_loss / len(dl)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIwiWvpRmGVg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
